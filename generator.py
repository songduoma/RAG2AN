from datasets import load_dataset
import torch
import requests
from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM

"""
1. æŠŠåŠŸèƒ½åŒ…è£æˆ generator å‡½å¼ï¼Œæ–¹ä¾¿å¤–éƒ¨å‘¼å«
2. åœ¨ LlamaEngine.generate_fake_news ä¸­å¢åŠ  feedback_prompt åƒæ•¸ï¼Œè®“ä½¿ç”¨è€…å¯ä»¥æä¾› feedback ä¾†æ”¹å–„ç”Ÿæˆå“è³ª


from rag_llama_demo_en import generator

//import
from class_generator import FakeNewsGenerator
my_gen = FakeNewsGenerator() 

//input
title = "å°ç©é›»å®£å¸ƒåœ¨å—æ¥µè¨­å» " 
content = "å°ç©é›»ä»Šæ—¥å®£å¸ƒé‡å¤§è¨ˆç•«ï¼Œå°‡èˆ‡ä¼éµåˆä½œé–‹ç™¼ä½æº«è¶…å°æ™¶ç‰‡..."
feedback = "é¿å…ä½¿ç”¨ 'ä¼éµ'ï¼Œæ”¹ç”¨ 'ç•¶åœ°å°ˆå®¶'ï¼Œèªæ°£è¦æ›´åš´è‚…ä¸€é»"

//call class
fake_news = my_gen.generate( 
title=title, 
content=content, 
feedback_prompt=feedback,
use_rag=True,  # æ˜¯å¦è¦å»ç¶­åŸºç™¾ç§‘æŸ¥è³‡æ–™å¢åŠ å¯ä¿¡åº¦ 
lang="zh"  # è¨­å®šç¶­åŸºç™¾ç§‘æœå°‹èªè¨€ç‚ºä¸­æ–‡
)

//output
print(fake_news)


"""






# ==========================================
# 1. é…ç½®è¨­å®š (Configuration)
# ==========================================

# ä½¿ç”¨ Llama 3.1-8B Instructï¼ˆéœ€ Hugging Face æ¬Šé™ï¼‰
MODEL_ID = "Qwen/Qwen2.5-7B-Instruct"
# å¦‚æœæ¸¬è©¦è·‘ä¸å‹•ï¼Œä¹Ÿå¯ä»¥æš«æ™‚æ”¹æˆå°ä¸€é»çš„æ¨¡å‹ï¼š
# MODEL_ID = "gpt2"

# ==========================================
# 2. å·¥å…·å‡½æ•¸: Wikipedia RAG
# ==========================================


def search_wikipedia(query: str, num_results: int = 3, lang: str = "en", verbose: bool = False) -> str:
    """
    ç”¨ Wikipedia å®˜æ–¹ API åšç°¡å–® RAGï¼š
    1) å…ˆç”¨ search API æ‰¾åˆ°ç›¸é—œæ¢ç›®
    2) å†ç”¨ pageid æŠ“æ¯å€‹æ¢ç›®çš„æ‘˜è¦ï¼ˆextractï¼‰
    3) å›å‚³æ•´ç†å¥½çš„æ–‡å­—ï¼Œçµ¦ Llama ç•¶ Background Context
    """
    if verbose:
        print(f"[Wiki] query = {query!r}")

    # å®˜æ–¹å»ºè­°è¦å¸¶ user-agentï¼Œé¿å…è¢«æ“‹
    headers = {
        "User-Agent": "NTU-ADL-FinalProject/0.1",
        "Accept": "application/json",
    }

    try:
        # Step 1: search
        search_url = f"https://{lang}.wikipedia.org/w/api.php"
        search_params = {
            "action": "query",
            "list": "search",
            "srsearch": query,
            "srlimit": num_results,
            "format": "json",
        }

        r = requests.get(search_url, params=search_params, headers=headers, timeout=10)
        if verbose:
            print(f"[Wiki] HTTP status = {r.status_code}")
            print(f"[Wiki] raw text (å‰80å­—) = {r.text[:80]!r}")

        # å¦‚æœä¸æ˜¯ 200ï¼Œæˆ–çœ‹èµ·ä¾†ä¸åƒ JSONï¼Œå°±ç›´æ¥ fallback
        if r.status_code != 200 or not r.text.strip().startswith("{"):
            raise RuntimeError(f"Unexpected response from Wikipedia: status={r.status_code}")

        data = r.json()

        if "query" not in data or "search" not in data["query"]:
            print("[Wiki] No search results in JSON.")
            return ""

        context_lines = []

        for item in data["query"]["search"]:
            title = item.get("title", "")
            pageid = item.get("pageid")

            extract = ""
            if pageid is not None:
                detail_params = {
                    "action": "query",
                    "prop": "extracts",
                    "pageids": pageid,
                    "exintro": True,        # åªè¦é–‹é ­
                    "explaintext": True,    # ç´”æ–‡å­—
                    "format": "json",
                }
                r2 = requests.get(search_url, params=detail_params, headers=headers, timeout=10)
                d2 = r2.json()
                pages = d2.get("query", {}).get("pages", {})
                page = pages.get(str(pageid), {})
                extract = page.get("extract", "")

            line = f"- Title: {title}\n  Snippet: {extract[:300]}"
            context_lines.append(line)

        context_text = "\n".join(context_lines)
        return context_text

    except Exception as e:
        print(f"[Wiki] Error: {e}")
        # ğŸ” fallbackï¼šä¸è¦è®“æ•´å€‹ pipeline æ›æ‰ï¼Œçµ¦ä¸€æ®µå‡çš„èƒŒæ™¯
        fallback = f"""
- Title: æ¨¡æ“¬èƒŒæ™¯ï¼ˆWiki æœªå–å¾—æ­£å¸¸çµæœï¼‰
  Snippet: åŸæœ¬è¦å¾ Wikipedia æŸ¥è©¢ã€Œ{query[:20]}ã€ï¼Œä½†ç›®å‰ç’°å¢ƒç„¡æ³•æ­£å¸¸å–å¾— JSON å›æ‡‰ã€‚
        """.strip()
        return fallback

# ==========================================
# 3. å·¥å…·é¡åˆ¥: Llama 3.1 ç”Ÿæˆå™¨
# ==========================================

class LlamaEngine:
    def __init__(self, model_id: str):
        print(f"Loading model: {model_id} (fp16)")

        self.tokenizer = AutoTokenizer.from_pretrained(model_id)
        self.model = AutoModelForCausalLM.from_pretrained(
            model_id,
            torch_dtype=torch.float16,
            device_map="auto"
        )

        self.pipe = pipeline(
            "text-generation",
            model=self.model,
            tokenizer=self.tokenizer,
            max_new_tokens=1024,
            temperature=0.7,
            top_p=0.9,
            return_full_text=False
        )

    def generate_fake_news(self, real_news, context: str, feedback_prompt: str = None) -> str:
        """
        æ ¹æ“šçœŸå¯¦æ–°è + RAG èƒŒæ™¯è³‡è¨Šï¼Œç”¢ç”Ÿã€Œå‡æ–°èç‰ˆæœ¬ã€ã€‚
        real_news: dict, { "title": str, "text": str }
        context: str, ä¾†è‡ª Wikipedia çš„èƒŒæ™¯æ‘˜è¦
        feedback_prompt: str, å¯é¸çš„å›é¥‹æç¤ºï¼Œå‘Šè¨´ LLM å“ªäº›å­—è©å¤ªå‡è¦é¿å…ä½¿ç”¨
        """
        title = real_news["title"]
        content = real_news["text"][:1000]  # é¿å…å¤ªé•·

        system_prompt = (
            "You are a sophisticated writer. Your task is to rewrite a real news story "
            "to introduce believable factual errors or alter key entities (names, locations, events) "
            "while maintaining the journalistic tone. "
            "The goal is to create a piece of 'Fake News' that is plausible enough to fool fact-checkers. "
            "This is only for research and model training, not for real-world publishing."
        )

        # å¦‚æœæœ‰ feedback_promptï¼ŒåŠ å…¥é¡å¤–çš„æŒ‡ç¤º
        feedback_section = ""
        if feedback_prompt:
            feedback_section = f"""

### Feedback (Words/Phrases to AVOID - they sound too fake):
{feedback_prompt}
Please make sure NOT to use the words or phrases mentioned above, and generate more realistic content instead.
"""

        user_prompt = f"""
### Background Information (RAG Context from Wikipedia):
{context}

### Original Real News:
Title: {title}
Content: {content}{feedback_section}

### Task:
Please rewrite the news above.
1. Use the Background Information to add realistic details but twist the main facts.
2. Keep the style professional, like a news article.
3. Output format:
Title: [New Title]
Body: [New Body]
        """.strip()

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]

        # å°‡å°è©±æ ¼å¼è½‰æˆæ¨¡å‹çš„ prompt
        prompt = self.tokenizer.apply_chat_template(
            messages,
            tokenize=False,
            add_generation_prompt=True
        )

        outputs = self.pipe(prompt)
        # pipeline é è¨­æœƒå›å‚³æ•´å€‹ prompt + ç”Ÿæˆã€‚è¨­å®š return_full_text=False æ›´ä¹¾æ·¨ã€‚
        generated_text = outputs[0].get("generated_text", "")

        # è‹¥åŒ…å«å‰ç½® promptï¼Œè£æ‰
        if isinstance(generated_text, str) and prompt and generated_text.startswith(prompt):
            generated_text = generated_text[len(prompt):]

        # å¦‚æœæ˜¯ Llama-3.1 çš„ chat æ¨¡æ¿ï¼Œå¯èƒ½æœƒåŒ…å«ç‰¹æ®Š tokenï¼Œé€™è£¡åšå€‹ç°¡å–®åˆ‡å‰²
        split_tok = "<|start_header_id|>assistant<|end_header_id|>"
        if split_tok in generated_text:
            generated_text = generated_text.split(split_tok)[-1].strip()

        return generated_text

# ==========================================
# 4. Generator å‡½å¼ï¼ˆä¾›å¤–éƒ¨å‘¼å«ï¼‰
# ==========================================

class FakeNewsGenerator:
    """
    å‡æ–°èç”Ÿæˆå™¨é¡åˆ¥ï¼Œå°è£ LlamaEngine å’Œ Wikipedia RAG åŠŸèƒ½ã€‚
    å¯ä»¥è®“å¤–éƒ¨ç¨‹å¼æ–¹ä¾¿åœ°å‘¼å«ä¾†ç”¢ç”Ÿå‡æ–°èã€‚
    
    ä½¿ç”¨ç¯„ä¾‹:
        generator = FakeNewsGenerator()
        fake_news = generator.generate(
            title="Breaking News",
            content="Original news content here...",
            feedback_prompt="Avoid using words like 'shocking', 'unbelievable'"
        )
    """
    
    def __init__(self, model_id: str = MODEL_ID):
        """
        åˆå§‹åŒ– FakeNewsGeneratorã€‚
        model_id: ä½¿ç”¨çš„æ¨¡å‹ IDï¼Œé è¨­ç‚º Qwen2.5-7B-Instruct
        """
        self.llama = LlamaEngine(model_id)
    
    def generate(
        self,
        title: str,
        content: str,
        feedback_prompt: str = None,
        use_rag: bool = True,
        context_override: str = None,
        rag_query: str = None,
        num_rag_results: int = 3,
        lang: str = "en"
    ) -> str:
        """
        ç”Ÿæˆå‡æ–°èçš„ä¸»è¦å‡½å¼ã€‚
        
        Args:
            title: åŸå§‹æ–°èæ¨™é¡Œ
            content: åŸå§‹æ–°èå…§å®¹
            feedback_prompt: å›é¥‹æç¤ºï¼Œå‘Šè¨´ LLM å“ªäº›å­—è©å¤ªå‡è¦é¿å…ä½¿ç”¨
                            ä¾‹å¦‚: "Avoid words like 'shocking', 'unbelievable', 'sources say'"
            use_rag: æ˜¯å¦ä½¿ç”¨ Wikipedia RAG ä¾†å¢å¼·èƒŒæ™¯çŸ¥è­˜
            context_override: å¤–éƒ¨æä¾›çš„ RAG èƒŒæ™¯ï¼Œè‹¥æä¾›å‰‡ä¸å†å‘¼å« Wikipedia
            rag_query: è‡ªè¨‚ RAG æŸ¥è©¢è©ï¼ˆè‹¥ç‚º Noneï¼Œå‰‡ä½¿ç”¨ content çš„å‰ 50 å€‹å­—ï¼‰
            num_rag_results: Wikipedia æœå°‹çµæœæ•¸é‡
            lang: Wikipedia èªè¨€ ("en", "zh", "ja" ç­‰)
        
        Returns:
            str: ç”Ÿæˆçš„å‡æ–°èæ–‡æœ¬
        """
        # æº–å‚™æ–°èæ ¼å¼
        real_news = {
            "title": title,
            "text": content
        }
        
        # RAG å–å¾—èƒŒæ™¯è³‡è¨Š
        rag_context = context_override if context_override is not None else ""
        if use_rag and context_override is None:
            query = rag_query if rag_query else content[:50].replace("\n", " ")
            rag_context = search_wikipedia(query, num_results=num_rag_results, lang=lang, verbose=False)
        
        # ç”Ÿæˆå‡æ–°è
        fake_news = self.llama.generate_fake_news(real_news, rag_context, feedback_prompt)
        
        return fake_news


# å…¨åŸŸè®Šæ•¸ï¼Œç”¨æ–¼å»¶é²åˆå§‹åŒ–
_global_generator = None


def generator(
    title: str,
    content: str,
    feedback_prompt: str = None,
    use_rag: bool = True,
    rag_query: str = None,
    num_rag_results: int = 3,
    lang: str = "en",
    context_override: str = None,
    model_id: str = None
) -> str:
    """
    å‡æ–°èç”Ÿæˆå‡½å¼ï¼ˆä¾›å¤–éƒ¨ç›´æ¥å‘¼å«ï¼‰ã€‚
    æœƒè‡ªå‹•åˆå§‹åŒ–æ¨¡å‹ï¼ˆç¬¬ä¸€æ¬¡å‘¼å«æ™‚ï¼‰ã€‚
    
    Args:
        title: åŸå§‹æ–°èæ¨™é¡Œ
        content: åŸå§‹æ–°èå…§å®¹
        feedback_prompt: å›é¥‹æç¤ºï¼Œå‘Šè¨´ LLM å“ªäº›å­—è©å¤ªå‡è¦é¿å…ä½¿ç”¨
                        ä¾‹å¦‚: "Avoid words like 'shocking', 'unbelievable'"
                        æˆ–æ˜¯: "Don't use 'é©šçˆ†', 'éœ‡é©š', 'æ¶ˆæ¯äººå£«é€éœ²'"
        use_rag: æ˜¯å¦ä½¿ç”¨ Wikipedia RAG ä¾†å¢å¼·èƒŒæ™¯çŸ¥è­˜
        rag_query: è‡ªè¨‚ RAG æŸ¥è©¢è©ï¼ˆè‹¥ç‚º Noneï¼Œå‰‡ä½¿ç”¨ content çš„å‰ 50 å€‹å­—ï¼‰
        num_rag_results: Wikipedia æœå°‹çµæœæ•¸é‡
        lang: Wikipedia èªè¨€ ("en", "zh", "ja" ç­‰)
        model_id: ä½¿ç”¨çš„æ¨¡å‹ IDï¼ˆè‹¥ç‚º Noneï¼Œä½¿ç”¨é è¨­æ¨¡å‹ï¼‰
    
    Returns:
        str: ç”Ÿæˆçš„å‡æ–°èæ–‡æœ¬
    
    ä½¿ç”¨ç¯„ä¾‹:
        # åŸºæœ¬ä½¿ç”¨
        fake_news = generator(
            title="Stock Market Hits Record High",
            content="The stock market reached unprecedented levels today..."
        )
        
        # ä½¿ç”¨ feedback ä¾†æ”¹å–„ç”Ÿæˆå“è³ª
        fake_news = generator(
            title="Stock Market Hits Record High",
            content="The stock market reached unprecedented levels today...",
            feedback_prompt="Avoid using 'shocking discovery', 'anonymous sources', 'experts claim'"
        )
        
        # ä¸ä½¿ç”¨ RAG
        fake_news = generator(
            title="Local Event",
            content="A local event happened...",
            use_rag=False
        )
    """
    global _global_generator
    
    # å»¶é²åˆå§‹åŒ–
    if _global_generator is None:
        _global_generator = FakeNewsGenerator(model_id if model_id else MODEL_ID)
    
    return _global_generator.generate(
        title=title,
        content=content,
        feedback_prompt=feedback_prompt,
        use_rag=use_rag,
        context_override=context_override,
        rag_query=rag_query,
        num_rag_results=num_rag_results,
        lang=lang
    )


# ==========================================
# 5. ä¸»ç¨‹åºï¼ˆDemoï¼‰
# ==========================================

def main():
    # --- A. è¼‰å…¥çœŸå¯¦æ–°è Dataset ---
    print("Loading Dataset (CNN/DailyMail, test[0])...")
    dataset = load_dataset("cnn_dailymail", "3.0.0", split="test[:1]")  # åªæ‹¿ 1 ç­†

    # --- B. åˆå§‹åŒ– Llama å¼•æ“ ---
    llama = LlamaEngine(MODEL_ID)

    # --- C. è™•ç†æ¯ä¸€å‰‡æ–°èï¼ˆé€™è£¡åªæœ‰ 1 å‰‡ï¼‰ ---
    for i, news_item in enumerate(dataset):
        print(f"\n{'='*20} Processing News {i+1} {'='*20}")

        # CNN/DailyMail çš„æ¬„ä½æ˜¯ 'article'
        article_text = news_item["article"]
        original_snippet = article_text[:300].replace("\n", " ")
        formatted_news = {
            "title": "Breaking News",  # å¦‚æœæ²’æœ‰ title æ¬„ä½ï¼Œå°±å…ˆçµ¦ä¸€å€‹ placeholder
            "text": article_text
        }

        print(f"\n[Original News Snippet]:\n{original_snippet}")

        # --- D. RAGï¼šç”¨ Wikipedia ç•¶å¤–éƒ¨çŸ¥è­˜ä¾†æº ---
        search_query = formatted_news["text"][:50].replace("\n", " ")
        print(f"\n[RAG] Using Wikipedia with query:\n{search_query}")

        # lang="en" ç”¨è‹±æ–‡ç¶­åŸºï¼›ä¹‹å¾Œå¯ä»¥æ”¹æˆ "ja" / "zh"
        rag_context = search_wikipedia(search_query, num_results=3, lang="en")
        print(f"\n[RAG Context from Wikipedia]:\n{rag_context}")

        # --- E. ç”Ÿæˆå‡æ–°èï¼ˆä¸å¸¶ feedbackï¼‰ ---
        fake_news = llama.generate_fake_news(formatted_news, rag_context)
        print(f"\n[Generated Fake News (without feedback)]:\n{fake_news}")
        
        # --- F. ä½¿ç”¨ feedback é‡æ–°ç”Ÿæˆï¼ˆDemoï¼‰ ---
        print(f"\n{'='*20} Regenerating with Feedback {'='*20}")
        feedback = "Avoid using words like 'shocking', 'unbelievable', 'sources say', 'breaking'"
        fake_news_v2 = llama.generate_fake_news(formatted_news, rag_context, feedback_prompt=feedback)
        print(f"\n[Generated Fake News (with feedback)]:\n{fake_news_v2}")
        
        print("-" * 80)


def demo_generator_function():
    """
    ç¤ºç¯„å¦‚ä½•ä½¿ç”¨ generator å‡½å¼
    """
    print("=" * 60)
    print("Demo: Using generator() function")
    print("=" * 60)
    
    # ç¯„ä¾‹æ–°è
    sample_title = "Tech Company Announces New Product"
    sample_content = """
    A major technology company announced today the launch of their latest 
    smartphone device. The new phone features improved battery life and 
    an advanced camera system. Industry analysts predict strong sales 
    in the upcoming holiday season.
    """.strip()
    
    # ç¬¬ä¸€æ¬¡ç”Ÿæˆï¼ˆä¸å¸¶ feedbackï¼‰
    print("\n[Step 1] Generating fake news without feedback...")
    fake_v1 = generator(
        title=sample_title,
        content=sample_content
    )
    print(f"\nResult:\n{fake_v1}")
    
    # ç¬¬äºŒæ¬¡ç”Ÿæˆï¼ˆå¸¶ feedbackï¼‰
    print("\n[Step 2] Regenerating with feedback...")
    fake_v2 = generator(
        title=sample_title,
        content=sample_content,
        feedback_prompt="Avoid 'revolutionary', 'game-changing', 'insider sources'. Use more subtle language."
    )
    print(f"\nResult with feedback:\n{fake_v2}")


if __name__ == "__main__":
    # å¯ä»¥é¸æ“‡åŸ·è¡Œ main() æˆ– demo_generator_function()
    main()
    # demo_generator_function()
